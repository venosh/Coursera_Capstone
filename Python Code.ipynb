{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score,f1_score,log_loss,classification_report,confusion_matrix,jaccard_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import pydotplus\n",
    "import matplotlib.image as mpimg\n",
    "from io import StringIO\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import folium\n",
    "import webbrowser\n",
    "from folium import plugins\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Importing Dataset\n",
    "main_df=pd.read_csv('C:\\\\Users\\\\Venos\\\\Desktop\\\\Capstone Project\\\\Car_Severity.csv')\n",
    "\n",
    "#Converting Severity Code from (1/2) tp (0/1)\n",
    "severity_code = main_df['SEVERITYCODE'].values\n",
    "\n",
    "labels = preprocessing.LabelEncoder()\n",
    "labels.fit([1, 2])\n",
    "severity_code = labels.transform (severity_code)\n",
    "\n",
    "main_df [\"SEVERITYCODE\"] = severity_code\n",
    "\n",
    "#Descriptive Stats\n",
    "descriptive_stats= main_df.describe(include=\"all\")\n",
    "\n",
    "    #Plotting counts of selected variables\n",
    "descriptive_stats_plot=descriptive_stats[[\"INATTENTIONIND\",\"UNDERINFL\",\"WEATHER\",\"ROADCOND\",\"LIGHTCOND\",\"SPEEDING\",\"SEVERITYCODE\"]]\n",
    "descriptive_stats_plot.drop(['unique','top','freq','mean','std','min','max','25%','50%','75%'],axis=0,inplace=True)\n",
    "descriptive_stats_plot=descriptive_stats_plot.transpose()\n",
    "\n",
    "color_yo=['sandybrown','sienna','sienna','sienna','sienna','sandybrown','sienna']\n",
    "descriptive_stats_plot.plot(kind='bar',alpha=0.70,color=[color_yo])\n",
    "plt.title('Number of entries in data for each variable - Seattle, Washington', fontsize=20, fontweight='bold')\n",
    "plt.xlabel(\"Variables\",fontsize=15,labelpad=20)\n",
    "plt.ylabel(\"Frequency\",fontsize=15,labelpad=20)\n",
    "plt.xticks(rotation=360)\n",
    "plt.show()\n",
    "\n",
    "#Area type of each accident\n",
    "explode_list = [0.05, 0.05, 0.2]\n",
    "color_list=['peachpuff','lightseagreen','darkorange']\n",
    "addtype=main_df['ADDRTYPE'].value_counts()\n",
    "\n",
    "addtype.plot(kind='pie',\n",
    "            figsize=(15, 6),\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90,\n",
    "            shadow=True,\n",
    "            labels=None,\n",
    "            pctdistance=1.12,\n",
    "            colors=color_list,\n",
    "            explode=explode_list)\n",
    "\n",
    "\n",
    "plt.title('Area of accident - Seattle, Washington', fontsize=18, y=1.05)\n",
    "plt.axis('equal')\n",
    "plt.legend(labels=addtype.index, loc='lower left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Check IncKey unqiue numbers\n",
    "main_df['INCKEY'].nunique()\n",
    "\n",
    "#Encoding in attention (0 = No, 1 = Yes)\n",
    "main_df[\"INATTENTIONIND\"].replace(\"Y\", 1, inplace=True)\n",
    "main_df[\"INATTENTIONIND\"].replace(np.nan, 0, inplace=True)\n",
    "\n",
    "#Encoding Under the influence (0 = No, 1 = Yes)\n",
    "main_df[\"UNDERINFL\"].replace(\"N\", 0, inplace=True)\n",
    "main_df[\"UNDERINFL\"].replace(\"Y\", 1, inplace=True)\n",
    "\n",
    "#Encoding Speeding(0 = No, 1 = Yes)\n",
    "main_df[\"SPEEDING\"].replace(\"Y\", 1, inplace=True)\n",
    "main_df[\"SPEEDING\"].replace(np.nan, 0, inplace=True)\n",
    "\n",
    "#Encoding Light Conditions(0 = Light, 1 = Medium, 2 = Dark)\n",
    "main_df[\"LIGHTCOND\"].replace(\"Daylight\", 0, inplace=True)\n",
    "main_df[\"LIGHTCOND\"].replace(\"Dark - Street Lights On\", 1, inplace=True)\n",
    "main_df[\"LIGHTCOND\"].replace(\"Dark - No Street Lights\", 2, inplace=True)\n",
    "main_df[\"LIGHTCOND\"].replace(\"Dusk\", 1, inplace=True)\n",
    "main_df[\"LIGHTCOND\"].replace(\"Dawn\", 1, inplace=True)\n",
    "main_df[\"LIGHTCOND\"].replace(\"Dark - Street Lights Off\", 2, inplace=True)\n",
    "main_df[\"LIGHTCOND\"].replace(\"Dark - Unknown Lighting\", 2, inplace=True)\n",
    "main_df[\"LIGHTCOND\"].replace(\"Other\",\"Unknown\", inplace=True)\n",
    "\n",
    "#Encoding Weather Conditions(0 = Clear, 1 = Overcast and Cloudy, 2 = Windy, 3 = Rain and Snow\n",
    "main_df[\"WEATHER\"].replace(\"Clear\", 0, inplace=True)\n",
    "main_df[\"WEATHER\"].replace(\"Raining\", 3, inplace=True)\n",
    "main_df[\"WEATHER\"].replace(\"Overcast\", 1, inplace=True)\n",
    "main_df[\"WEATHER\"].replace(\"Other\", \"Unknown\", inplace=True)\n",
    "main_df[\"WEATHER\"].replace(\"Snowing\", 3, inplace=True)\n",
    "main_df[\"WEATHER\"].replace(\"Fog/Smog/Smoke\", 2, inplace=True)\n",
    "main_df[\"WEATHER\"].replace(\"Sleet/Hail/Freezing Rain\", 3, inplace=True)\n",
    "main_df[\"WEATHER\"].replace(\"Blowing Sand/Dirt\", 2, inplace=True)\n",
    "main_df[\"WEATHER\"].replace(\"Severe Crosswind\", 2, inplace=True)\n",
    "main_df[\"WEATHER\"].replace(\"Partly Cloudy\", 1, inplace=True)\n",
    "\n",
    "#Encoding Road Conditions(0 = Dry, 1 = Mushy, 2 = Wet)\n",
    "main_df[\"ROADCOND\"].replace(\"Dry\", 0, inplace=True)\n",
    "main_df[\"ROADCOND\"].replace(\"Wet\", 2, inplace=True)\n",
    "main_df[\"ROADCOND\"].replace(\"Ice\", 2, inplace=True)\n",
    "main_df[\"ROADCOND\"].replace(\"Snow/Slush\", 1, inplace=True)\n",
    "main_df[\"ROADCOND\"].replace(\"Other\", \"Unknown\", inplace=True)\n",
    "main_df[\"ROADCOND\"].replace(\"Standing Water\", 2, inplace=True)\n",
    "main_df[\"ROADCOND\"].replace(\"Sand/Mud/Dirt\", 1, inplace=True)\n",
    "main_df[\"ROADCOND\"].replace(\"Oil\", 2, inplace=True)\n",
    "\n",
    "\n",
    "#Making new dataframe with only variables and unique keys\n",
    "selected_columns=main_df[[\"X\",\"Y\",\"INCKEY\",\"INATTENTIONIND\",\"UNDERINFL\",\"WEATHER\",\"ROADCOND\",\"LIGHTCOND\",\"SPEEDING\",\"SEVERITYCODE\"]]\n",
    "feature_df=selected_columns.copy()\n",
    "feature_df.dropna(axis=0,how='any',inplace=True)\n",
    "feature_stats=feature_df.describe()\n",
    "\n",
    "np.count_nonzero(feature_df['UNDERINFL'])\n",
    "\n",
    "    #Light Condition\n",
    "lightcondsize = feature_df [\"LIGHTCOND\"].size\n",
    "\n",
    "featureinlightcond = feature_df ['LIGHTCOND'] == 'Unknown'\n",
    "\n",
    "lightcond = feature_df['LIGHTCOND']\n",
    "lightcond = lightcond.values\n",
    "lightcond = lightcond[featureinlightcond]\n",
    "\n",
    "lightcond[0:9036]=0\n",
    "lightcond[9036:13417]=1\n",
    "lightcond[13417:13961]=2\n",
    "\n",
    "feature_df.loc [feature_df.LIGHTCOND == \"Unknown\", 'LIGHTCOND'] = lightcond\n",
    "\n",
    "feature_df[\"LIGHTCOND\"]=feature_df[\"LIGHTCOND\"].astype(int)\n",
    "\n",
    "    #Road Condition\n",
    "roadcondsize = feature_df [\"ROADCOND\"].size\n",
    "\n",
    "featureinroadcond = feature_df ['ROADCOND'] == 'Unknown'\n",
    "\n",
    "roadcond = feature_df['LIGHTCOND']\n",
    "roadcond = roadcond.values\n",
    "roadcond = roadcond[featureinroadcond]\n",
    "\n",
    "roadcond[0:9954]=0\n",
    "roadcond[9954:10040]=1\n",
    "roadcond[10040:15163]=2\n",
    "\n",
    "feature_df.loc[feature_df.ROADCOND == \"Unknown\", 'ROADCOND'] = roadcond\n",
    "feature_df[\"ROADCOND\"]=feature_df[\"ROADCOND\"].astype(int)\n",
    "\n",
    "    #Weather Condition\n",
    "weathersize = feature_df [\"WEATHER\"].size\n",
    "\n",
    "featureinweather = feature_df ['WEATHER'] == 'Unknown'\n",
    "\n",
    "weather = feature_df['WEATHER']\n",
    "weather = weather.values\n",
    "weather = weather[featureinweather]\n",
    "\n",
    "weather[0:10151]=0\n",
    "weather[10151:12683]=1\n",
    "weather[12683:12742]=2\n",
    "weather[12742:15864]=3\n",
    "\n",
    "feature_df.loc[feature_df.WEATHER == \"Unknown\", 'WEATHER'] = weather\n",
    "feature_df[\"WEATHER\"]=feature_df[\"WEATHER\"].astype(int)\n",
    "\n",
    "    #Converting remaining to int\n",
    "feature_df[\"SPEEDING\"]=feature_df[\"SPEEDING\"].astype(int)\n",
    "feature_df[\"INATTENTIONIND\"]=feature_df[\"INATTENTIONIND\"].astype(int)\n",
    "feature_df[\"UNDERINFL\"]=feature_df[\"UNDERINFL\"].astype(int)\n",
    "\n",
    "\n",
    "#ML Feature Sets\n",
    "X=feature_df[[\"SPEEDING\",\"INATTENTIONIND\",\"UNDERINFL\",\"ROADCOND\",\"WEATHER\",\"LIGHTCOND\"]].values\n",
    "y=feature_df[[\"SEVERITYCODE\"]].values\n",
    "\n",
    "#Test/Train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)\n",
    "\n",
    "# Balance the Data\n",
    "os = SMOTE (random_state=0)\n",
    "os_data_X, os_data_y= os.fit_sample(X_train, y_train)\n",
    "\n",
    "#Make reduced df from feature_df to get a few random points to make map\n",
    "limit = 100005\n",
    "reduced_df = feature_df.iloc [0:limit:5, 0:]\n",
    "\n",
    "#Folium Map\n",
    "# let's start again with a clean copy of the map of San Francisco\n",
    "seattle_map = folium.Map(location=[47.61536892, -122.3302243], zoom_start=10)\n",
    "\n",
    "# instantiate a mark cluster object for the incidents in the dataframe\n",
    "incidents = plugins.MarkerCluster().add_to(seattle_map)\n",
    "\n",
    "# loop through the dataframe and add each data point to the mark cluster\n",
    "for lat, lng, label, in zip(reduced_df.Y, reduced_df.X, reduced_df.SEVERITYCODE):\n",
    "    folium.Marker(\n",
    "    location=[lat, lng],\n",
    "    icon=None,\n",
    "    popup=label,\n",
    "    ).add_to(incidents)\n",
    "\n",
    "seattle_map.add_child(incidents)\n",
    "\n",
    "# display map\n",
    "seattle_map\n",
    "seattle_map.save(\"seattlemap.html\")\n",
    "webbrowser.open(\"seattlemap.html\")\n",
    "\n",
    "#Decision Tree Clasifier\n",
    "DT = DecisionTreeClassifier(criterion=\"entropy\", max_depth=6)\n",
    "DT.fit(os_data_X,os_data_y)\n",
    "\n",
    "        #Make Prediction:\n",
    "yhatDT = DT.predict(X_test)\n",
    "\n",
    "        #Check Accuracy\n",
    "print('Accuracy score for Decision Tree = ', accuracy_score(yhatDT, y_test))\n",
    "\n",
    "        #Visualization\n",
    "print('Confusion Matrix - Decision Tree')\n",
    "print(pd.crosstab(y_test.ravel(), yhatDT.ravel(), rownames = ['True'], colnames = ['Predicted'], margins = True))\n",
    "\n",
    "print(classification_report(yhatDT,y_test))\n",
    "\n",
    "        #COnfusion Matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    #Plot it\n",
    "cnf_matrix = confusion_matrix(y_test, yhatDT, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "        # Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Injury=1','Property Damage=0'],normalize= False,  title='Confusion matrix')\n",
    "\n",
    "#Logistic Regression\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(os_data_X,os_data_y)\n",
    "\n",
    "yhatLR = LR.predict(X_test)\n",
    "yhat_prob = LR.predict_proba(X_test)\n",
    "\n",
    "print(log_loss(y_test, yhat_prob))\n",
    "\n",
    "print (\"Accuracy\", accuracy_score(yhatLR,y_test))\n",
    "print (classification_report(y_test, yhatLR))\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, yhatLR, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "        # Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Injury=1','Property Damage=0'],normalize= False,  title='Confusion matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
